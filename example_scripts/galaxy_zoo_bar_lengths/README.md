### Galaxy Zoo Bar Lengths Analysis

GZBL was launched the same day Panoptes launched (it was one of the 4 original projects). The project has 1 workflow, which combines question tasks and 1 marking task where users are asked to draw 2 lines per subject (though note: the project operated before it was possible to limit the user to a specific number of markings). The question tree is branched, but simply so: the first question is a Yes/No question, and if you answer No you move on to the next subject, and if you answer Yes you answer all the remaining questions (including the drawing task).

We used the Zooniverse's [aggregation](https://github.com/zooniverse/aggregation) engine to aggregate the question-tree questions (we applied no user weighting). But on the drawing question, the aggregations from the generalized software just weren't quite right -- we needed slightly different settings, and there was also a bug present for the first few Zooniverse projects (including GZBL) that made the aggregation software (tested after the bug was fixed) less optimal.

So, the scripts here are meant to aggregate the line drawings from the drawing task. They are:

 - `extract_line_drawings.py` - Ingest the raw classifications export and output a file containing one mark per line. So if a user drew 2 lines on a subject during a classification, the output file would have 2 extra rows as a result of that classification. The output of this script is used by subsequent scripts.

 - `cluster_line_markings.py` - Runs a clustering algorithm on the line markings for each subject in order to find the most likely true marks (this project measures the length and width of a thing on an image). There are four clustering methods you can use (well, it's all hierarchical clustering, but there are 4 ways to agglomerate the drawings into clusters): single, complete, average, and ward. Outputs each cluster's line properties (2 sets, actually, one using the median and one using the mean) as well as the number of marks that went into it, and a quantity called `p_true_positive` that, in theory, gives the probability that the cluster is real (it's actually the fraction of classifications that contributed a line to that cluster, which is likely closely related to a probability). *Note:* the parameters of the clustering algorithm are optimized to produce 2 clusters per drawing, because that's what we asked for (that's also what the vast majority of people drew). You might have a different optimal setting for your project.

 - `choose_line_length_width.py` - This takes the output of the clustering algorithm and decides, for each subject, whether it has reliable measurements, and if so, which measurements are the length and which are the width. It then writes to a file that has just a length and a width per subject (if it's appropriate for the subject to have measurements - not all of them actually have the feature).

 - `draw_lines_on_images.py` - I was really not sure which of the clustering methods (single, complete, average or ward) would produce the best results for me, so I wrote this code to intake the results of each method and produce one big mosaic-image per subject that had the raw drawings and the aggregated drawings from each method, plus the overall properties of the classification (how many people said it had the feature etc). This program makes a LOT of image files - the project had something like 5000 subjects with aggregated markings.

Hopefully the code itself is reasonably well documented, but post an [issue](https://github.com/zooniverse/Data-digging/issues) and tag @vrooje if you have questions that don't have clear answers from trying out/looking at the code.
